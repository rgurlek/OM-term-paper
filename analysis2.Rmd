---
title: "Analysis"
author: "Ragip Gurlek"
date: "4/17/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F)
```

```{r}
library(tidyr)
library(plyr)
library(dplyr)
library(sf)
library(knitr)
library(summarytools)
library(stargazer)
library(ggplot2)
library(interplot)
seed <- 8234
```


```{r}
# Plot the sampled border points ####
point_sample <- list()
for(i in seq(1234, seed, 1000)){
  point_sample <- c(point_sample, readRDS(paste0("point_sample_", seed, ".rds")))
}
plot(st_geometrycollection(point_sample))
length(point_sample)

remove(point_sample)
```

```{r}
# Obsorve number of clusters with each nrow value
rest_data <- list()
for(i in seq(1234, seed, 1000)){
  rest_data <- c(rest_data, readRDS(paste0("rest_data_", seed, ".rds")))
}
table(sapply(rest_data, nrow))
sum(sapply(rest_data, nrow))

# Number of unique restaurants in the data
id_list <- lapply(rest_data, function(x) x$id)
id_list <- unlist(id_list)
length(unique(id_list))
```

```{r}
# An example from the original data ####
library(yelpr)

key <- readLines("api_key.txt")
radius = 16000 # about 10 miles
longitude <-  -84.358739
latitude <- 33.762607
bus_data <- suppressMessages(business_search(
  api_key = key,
  latitude = latitude,
  longitude = longitude,
  radius = radius,
  limit = 50,
  term = "restaurants"
))
bus_data <- bus_data$businesses
bus_data$categories
```

# Descriptive Stats From Raw Data

```{r}
raw_data <- read.csv("raw_data2.csv")
state_counts <- table(raw_data$state)
state_counts <- sort(state_counts, decreasing = T)
length(state_counts)
```

```{r eval=FALSE, include=FALSE}
# Report confidence intervals in paper.
# For the presentation, significance is not important. Just show means. The 
# Focal assignment is random. The significance might be due to high n. The 
# confidence intervals are economically ignorable.
```

```{r, results='asis'}
stargazer(raw_data[,c(7,8,6, 14:18)],
          title = "Descriptive statistics",
          label = "Desc",
          header = F,
          notes = "CombinedRate is sum all sales taxes")
```


```{r}
# Variable means
summary_table <- aggregate(raw_data[, c("rating", "price", "CombinedRate", "review_count")],
          list(raw_data$is_focal), mean, na.rm = T)[,2:5]
rownames(summary_table) <- c("Non-focal", "Focal")
summary_table <- summary_table[, c(1, 2, 4, 3)]
stargazer(summary_table, summary = F,
          title = "Comparison of means for focal and non-focal groups",
          label = "versus",
          header = F,
          notes = "CombinedRate is sum all sales taxes")
```

```{r}
# Variable sd
summary_table <- aggregate(raw_data[, c("rating", "price", "CombinedRate", "review_count")],
          list(raw_data$is_focal), sd, na.rm = T)[,2:5]
rownames(summary_table) <- c("Non-focal", "Focal")
kable(summary_table, digits = c(3,3,4,2),
      caption = "Non-focal vs Focal Standard Deviations")
```

```{r}
# Rating t-test for focal vs non-focal
focal <- raw_data[raw_data$is_focal, ]
non_focal <- raw_data[!raw_data$is_focal, ]
t.test(focal$rating, non_focal$rating)
```

```{r}
# Price t-test for focal vs non-focal
t.test(focal$price, non_focal$price)
```

```{r}
# CombinedRate t-test for focal vs non-focal
t.test(focal$CombinedRate, non_focal$CombinedRate)
```

```{r}
# StateRate t-test for focal vs non-focal
t.test(focal$StateRate, non_focal$StateRate)
```

```{r}
# CityRate t-test for focal vs non-focal
t.test(focal$CityRate, non_focal$CityRate)
```

```{r}
# Review Count t-test for focal vs non-focal
t.test(focal$review_count, non_focal$review_count)
```

# Regression

```{r}
reg_data <- read.csv("reg_data2.csv")
```

```{r}
cols <- c("StateRate", "CountyRate", "CityRate", "SpecialRate")
selected_cols <- reg_data[,cols]
selected_cols$combined <- rowSums(selected_cols)
ggplot(gather(selected_cols), aes(value)) + 
    geom_histogram(bins = 100) + 
    facet_wrap(~key, scales = 'free_x')
```
## First stage regression
```{r}
library(AER)
# cor(reg_data[,sapply(reg_data, is.numeric)])
model <- lm(price ~ StateRate + CountyRate + CityRate + SpecialRate,
            data = reg_data)
coeftest(model, vcov. = vcovHC, type = "HC2")
```

## IV model

```{r warning=FALSE, results='asis'}

iv_model_1 <- ivreg(rating ~ price |
                      StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
iv_model_2 <- ivreg(rating ~ price  + log(review_count+1951)|
                    log(review_count+1951) +
                    StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
# White standard errors
test1 <- coeftest(iv_model_1, vcov. = vcovHC, type = "HC2")
test2 <- coeftest(iv_model_2, vcov. = vcovHC, type = "HC2")
# stargazer(iv_model, type = "html",
#           covariate.labels = c("log(review\\_count)", NA),
#           notes = "IVs used for price: StateRate, CountyRate, CityRate, SpecialRate",
#           notes.append = T)
```

```{r eval=FALSE, include=FALSE}
stargazer(iv_model_1, iv_model_2,
          intercept.bottom = F, intercept.top = F, header = F,
          covariate.labels = c(NA, "log(review\\_count)"),
          se = list(test1[, 2], test2[, 2]),
          pe = list(test1[, 4], test2[, 4]),
          notes = c("Instruments used for price: StateRate, CountyRate, CityRate, SpecialRate.", "Heteroscedasticity-consistent standard errors are reported in parentheses."),
          notes.append = T, omit = "Constant",
          omit.table.layout = "s",
          label = "regression",
          title = "IV estimate of the effect of price with and without review count")
```

# Robustness for radius
```{r warning=FALSE, results='asis'}
reg_data <- read.csv("reg_data_8046.csv")
iv_model_1 <- ivreg(rating ~ price |
                      StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
iv_model_2 <- ivreg(rating ~ price  + log(review_count+1951)|
                    log(review_count+1951) +
                    StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
test1 <- coeftest(iv_model_1, vcov. = vcovHC, type = "HC2")
test2 <- coeftest(iv_model_2, vcov. = vcovHC, type = "HC2")

reg_data <- read.csv("reg_data_4023.csv")
iv_model_3 <- ivreg(rating ~ price |
                      StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
iv_model_4 <- ivreg(rating ~ price  + log(review_count+1951)|
                    log(review_count+1951) +
                    StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
test3 <- coeftest(iv_model_3, vcov. = vcovHC, type = "HC2")
test4 <- coeftest(iv_model_4, vcov. = vcovHC, type = "HC2")

reg_data <- read.csv("reg_data_1609.csv")
iv_model_5 <- ivreg(rating ~ price |
                      StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
iv_model_6 <- ivreg(rating ~ price  + log(review_count+1951)|
                    log(review_count+1951) +
                    StateRate + CountyRate + CityRate + SpecialRate,
                  data = reg_data)
test5 <- coeftest(iv_model_5, vcov. = vcovHC, type = "HC2")
test6 <- coeftest(iv_model_6, vcov. = vcovHC, type = "HC2")
```


```{r eval=FALSE, include=FALSE}
stargazer(iv_model_1, iv_model_2, iv_model_3, iv_model_4, iv_model_5, iv_model_6,
          intercept.bottom = F, intercept.top = F, header = F,
          covariate.labels = c(NA, "log(review\\_count)"),
          se = list(test1[, 2], test2[, 2], test3[, 2], test4[, 2], test5[, 2], test6[, 2]),
          pe = list(test1[, 4], test2[, 4], test3[, 4], test4[, 4], test5[, 4], test6[, 4]),
          column.labels = c("5 miles", "5 miles", "2.5 miles", "2.5 miles", "1 miles", "1 miles"),
          notes = c("Instruments used for price: StateRate, CountyRate, CityRate, SpecialRate.", "Heteroscedasticity-consistent standard errors are reported in parentheses."),
          notes.append = T, omit = "Constant",
          omit.table.layout = "s",
          label = "robust",
          title = "IV estimate of the effect of price on rating for different radius choices")
```

```{r}
hist(reg_data$price, xlab = "price", main = "Histogram of price")
```
# Heterogeneity Regressions

## Price level heterogeneity
Does the placebo effect more prevalent for more expensive restaurants? Will
multicollinearity be an issue?


## Income level heterogeneity

```{r}
income <- read.csv("median income by zipcode - PolicyMap.csv",
                   nrows = 33144, na.strings = "N/A")
income <- income[,c(1,5)]
colnames(income) <- c("zip_code","median_income")
income$zip_code <- as.numeric(as.character(income$zip_code))
reg_data <- merge(reg_data, raw_data[,c('id', 'zip_code')], by = "id", all.x = T)
reg_data <- merge(reg_data, income, by = "zip_code", all.x = T)
```

I lose 150 observations with NA median income.

```{r}
hist(reg_data$median_income)
hist(log(reg_data$median_income))
my_df <- reg_data[, c("price", "median_income")]
my_df <- reg_data[complete.cases(my_df), ]
cor(my_df$price, log(my_df$median_income))
income_inter <- ivreg(rating ~ log(review_count+1951) +
                        price*log(median_income) |
                        log(review_count+1951) + log(median_income) +
                        StateRate + CountyRate + CityRate + SpecialRate,
                      data = my_df)

# Standard error - Confidence Interval for interaction
coefs <- coeftest(income_inter, vcov. = vcovHC, type = "HC2")
my_vcov <- vcovHC(income_inter, type = "HC2")
x_values <- seq(min(log(my_df$median_income)), max(log(my_df$median_income)),
    length.out = 500)
effect <- coefs[3, 1] + coefs[5, 1] * x_values
se <- sqrt(my_vcov[3,3] + my_vcov[5,5] * x_values^2 +
             2 * my_vcov[3,5] * x_values)
lb <- effect - se*1.96
ub <- effect + se*1.96
plot_df <- data.frame(x_values, effect, lb, ub)
pdf("hetero.pdf", width=10, height=5)
ggplot(plot_df, aes(x=x_values)) + 
  geom_line(aes(y = effect), color = "darkred") + 
  geom_line(aes(y = lb), color="steelblue", linetype="twodash") +
  geom_line(aes(y = ub), color="steelblue", linetype="twodash") +
  xlab("Median income (logarithmic scale)") +
  ylab("Effect of price on rating") +
  theme(text = element_text(size=15))
dev.off()
```

```{r eval=FALSE, include=FALSE, results='asis'}
library(AER)

set.seed(seed)
reg_data <- read.csv("reg_data2.csv")
reg_data <- reg_data[sample(nrow(reg_data)), ]
reg_data <- reg_data[!duplicated(reg_data$id), ]

model <- ivreg(rating ~ log(review_count+1951) + price + I(price^2)|
                 log(review_count+1951) + StateRate +
                 CountyRate + CityRate + SpecialRate, data = reg_data)

summary(model)
library(ggeffects)
mydf <- ggpredict(model, terms = "price [all]")
plot(mydf)
```

```{r eval=FALSE, include=FALSE}
model <- lm(rating ~ StateRate + CountyRate + CityRate + SpecialRate,
            data = reg_data)
summary(model)

model <- lm(rating ~ review_count + price, data = reg_data)
summary(model)


model <- ivreg(rating ~ review_count + price| review_count + CombinedRate,
               data = reg_data)
summary(model)

model <- lm(price ~ CombinedRate, data = reg_data)
summary(model)

library(ggplot2)
ggplot(reg_data, aes(x = price, y = rating)) +
  geom_point()

```


## Latex

```{r eval=FALSE, include=FALSE, results='asis'}
stargazer(descr(raw_data[,6:8],
      stats = c("min", "q1", "med", "mean", "q3", "max"),
      style = "rmarkdown"),
      order = c(1,3,2,4))
```

```{r eval=FALSE, include=FALSE, results='asis'}
stargazer(descr(raw_data[,14:18],
      stats = c("min", "q1", "med", "mean", "q3", "max"),
      style = "rmarkdown"),
      order = c(1, 6, 2, 4, 5, 3))
```

```{r eval=FALSE, include=FALSE}
# Variable means
summary_table <- aggregate(raw_data[, c("rating", "price", "CombinedRate", "review_count")],
          list(raw_data$is_focal), mean, na.rm = T)[,2:5]
rownames(summary_table) <- c("Non-focal", "Focal")
summary_table <- mapply(round, summary_table, c(3,3,4,2))
summary_table <- apply(summary_table, 2, as.character)
stargazer(summary_table, summary = F)
```




