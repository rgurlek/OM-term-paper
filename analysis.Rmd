---
title: "Analysis"
author: "Ragip Gurlek"
date: "4/17/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F)
```

```{r}
library(tidyr)
library(dplyr)
library(plyr)
library(sf)
library(knitr)
library(summarytools)
library(stargazer)
library(ggplot2)
library(margins)
seed <- 8234
```


```{r}
# Plot the sampled border points ####
point_sample <- list()
for(i in seq(1234, seed, 1000)){
  point_sample <- c(point_sample, readRDS(paste0("point_sample_", seed, ".rds")))
}
plot(st_geometrycollection(point_sample))
length(point_sample)

remove(point_sample)
```

```{r}
# Obsorve number of clusters with each nrow value
rest_data <- list()
for(i in seq(1234, seed, 1000)){
  rest_data <- c(rest_data, readRDS(paste0("rest_data_", seed, ".rds")))
}
table(sapply(rest_data, nrow))
sum(sapply(rest_data, nrow))

id_list <- lapply(rest_data, function(x) x$id)
id_list <- unlist(id_list)
length(unique(id_list))
```

```{r}
# An example from the original data ####
library(yelpr)

key <- readLines("api_key.txt")
radius = 16000 # about 10 miles
longitude <-  -84.358739
latitude <- 33.762607
bus_data <- suppressMessages(business_search(
  api_key = key,
  latitude = latitude,
  longitude = longitude,
  radius = radius,
  limit = 50,
  term = "restaurants"
))
bus_data <- bus_data$businesses
bus_data$categories
```

# Descriptive Stats From Raw Data

```{r}
raw_data <- read.csv("raw_data2.csv")
state_counts <- table(raw_data$state)
state_counts <- sort(state_counts, decreasing = T)
length(state_counts)
```

```{r eval=FALSE, include=FALSE}
unique_data <- raw_data[!duplicated(raw_data$id), ]
table(unique_data$is_focal)

ids <- unlist(sapply(rest_data, function(x) x$id))
length(unique(ids))
```

```{r eval=FALSE, include=FALSE}
# Report confidence intervals in paper.
# For the presentation, significance is not important. Just show means. The 
# Focal assignment is random. The significance might be due to high n. The 
# confidence intervals are economically ignorable.
```

```{r, results='asis'}
descr(raw_data[,c(6:9, 14:18)],
      stats = c("min", "q1", "med", "mean", "q3", "max"),
      style = "rmarkdown")
```


```{r}
# Variable means
summary_table <- aggregate(raw_data[, c("rating", "price", "CombinedRate", "review_count")],
          list(raw_data$is_focal), mean, na.rm = T)[,2:5]
rownames(summary_table) <- c("Non-focal", "Focal")
kable(summary_table, digits = c(3,3,4,2),
      caption = "Non-focal vs Focal Means")
```

```{r}
# Variable sd
summary_table <- aggregate(raw_data[, c("rating", "price", "CombinedRate", "review_count")],
          list(raw_data$is_focal), sd, na.rm = T)[,2:5]
rownames(summary_table) <- c("Non-focal", "Focal")
kable(summary_table, digits = c(3,3,4,2),
      caption = "Non-focal vs Focal Standard Deviations")
```

```{r}
# Rating t-test for focal vs non-focal
focal <- raw_data[raw_data$is_focal, ]
non_focal <- raw_data[!raw_data$is_focal, ]
t.test(focal$rating, non_focal$rating)
```

```{r}
# Price t-test for focal vs non-focal
t.test(focal$price, non_focal$price)
```

```{r}
# CombinedRate t-test for focal vs non-focal
t.test(focal$CombinedRate, non_focal$CombinedRate)
```

```{r}
# StateRate t-test for focal vs non-focal
t.test(focal$StateRate, non_focal$StateRate)
```

```{r}
# CityRate t-test for focal vs non-focal
t.test(focal$CityRate, non_focal$CityRate)
```

```{r}
# Review Count t-test for focal vs non-focal
t.test(focal$review_count, non_focal$review_count)
```

# Regression

```{r}
reg_data <- read.csv("reg_data2.csv")
min(reg_data$review_count)
```

```{r}
cols <- c("StateRate", "CountyRate", "CityRate", "SpecialRate")
selected_cols <- reg_data[,cols]
selected_cols$combined <- rowSums(selected_cols)
ggplot(gather(selected_cols), aes(value)) + 
    geom_histogram(bins = 100) + 
    facet_wrap(~key, scales = 'free_x')
```
## First stage regression
```{r}
library(AER)
cor(reg_data[,c("StateRate", "CountyRate", "CityRate", "SpecialRate", "CombinedRate",
                "price")])
model <- lm(price ~ StateRate + CountyRate + CityRate + SpecialRate,
            data = reg_data)
coeftest(model, vcov. = vcovHC, type = "HC2")
```

## Linear model

```{r warning=FALSE, results='asis'}

linear_model <- ivreg(rating ~ log(review_count+1951) + price | log(review_count+1951) + StateRate +
                 CountyRate + CityRate + SpecialRate, data = reg_data)
coeftest(linear_model, vcov. = vcovHC, type = "HC2")
# stargazer(linear_model, type = "html",
#           covariate.labels = c("log(review\\_count)", NA),
#           notes = "IVs used for price: StateRate, CountyRate, CityRate, SpecialRate",
#           notes.append = T)
```

## Non-lienar model

```{r, results='asis'}
nonlinear_model <- ivreg(rating ~ log(review_count+1951) + price + I(price^2)|
                 log(review_count+1951) + StateRate +
                 CountyRate + CityRate + SpecialRate, data = reg_data)
coeftest(nonlinear_model, vcov. = vcovHC, type = "HC2")
# stargazer(nonlinear_model, type = "html",
#           covariate.labels = c("log(review\\_count)", NA, "price$^2$"),
#           notes = "IVs used for price: StateRate, CountyRate, CityRate, SpecialRate",
#           notes.append = T)
```

```{r}
stargazer(linear_model, nonlinear_model,
          covariate.labels = c("log(review\\_count)", NA, "price$^2$"),
          notes = "IVs used for price: StateRate, CountyRate, CityRate, SpecialRate",
          notes.append = T)
```

This plot shows the prediction for Delta rating, not the effect (coefficient).
It tells us that if I am cheaper than average of my neighbor restaurants,
I am rated lower than them. Being a little bit expensive than the average slightly helps.
However, after a point, it hurts the ratings. Specifically, being more expensive
by a value between 0.26 and 0.64 significantly improves the ratings. The maximum effect
is achived when the difference is 0.45, which improves the rating by 0.08.
Being more expensive than the avereage by a value more than 0.92 hurts the rating
although this effect is not significant due to high standard errors in that
region.
Note that these results are obtained after controlling for confounders like quality
(thanks to IV and matching).

```{r}
library(ggeffects)
mydf <- ggpredict(nonlinear_model, terms = "price [all]")
attributes(mydf)$title <- "Prediction of deviance from mean Rating given deviance from mean Price"
attributes(mydf)$x.title <- "Delta Price"
attributes(mydf)$y.title <- "Delta Rating"
plot(mydf)
mydf[abs(mydf$predicted) < 0.001, ]
signi_improve <- mydf[mydf$conf.low >0, ]
signi_improve[c(1,nrow(signi_improve)), ]
signi_improve[which.max(signi_improve$predicted), ]
```

```{r}
hist(reg_data$price, xlab = "price", main = "Histogram of price")
```
# Heterogeneity Regressions

## Price level heterogeneity
Does the placebo effect more prevalent for more expensive restaurants? Will
multicollinearity be an issue?

```{r}
colnames(raw_data)[colnames(raw_data) == "price"] <- "abs_price"
reg_data <- merge(reg_data, raw_data[, c("id", "abs_price", "zip_code")],
                  by = "id", all.x = T)
cor(reg_data$price, reg_data$abs_price)
cor(reg_data$price, reg_data$abs_price - reg_data$price)
```

This is a huge correlation! The correlation with the average competitor prices
is lower. However, regression for that one is weird.

```{r}
reg_data$neigh_average <- reg_data$abs_price - reg_data$price
abs_price_inter <- ivreg(rating ~ log(review_count+1951) + price*abs_price |
                        log(review_count+1951) + StateRate +
                 CountyRate + CityRate + SpecialRate, data = reg_data)
coeftest(abs_price_inter, vcov. = vcovHC, type = "HC2")
```

For price levels 1 and 2, there is no placebo. For 3 and 4, there is. However,
the significance of these should be tested. Can I find a way to deal with
multicolliniarity?

## Income level heterogeneity

```{r}
income <- read.csv("median income by zipcode - PolicyMap.csv",
                   nrows = 33144, na.strings = "N/A")
income <- income[,c(1,5)]
colnames(income) <- c("zip_code","median_income")
income$zip_code <- as.numeric(as.character(income$zip_code))
reg_data <- merge(reg_data, income, by = "zip_code", all.x = T)
```

I lose 150 observations with NA median income.

```{r}
hist(reg_data$median_income)
hist(log(reg_data$median_income))
income_inter <- ivreg(rating ~ log(review_count+1951) + price * log(median_income) |
                        log(review_count+1951) + StateRate +
                 CountyRate + CityRate + SpecialRate, data = reg_data)
coeftest(income_inter, vcov. = vcovHC, type = "HC2")
coef(income_inter)[3] + coef(income_inter)[5] * min(log(reg_data$median_income), na.rm = T)
coef(income_inter)[3] + coef(income_inter)[5] * max(log(reg_data$median_income), na.rm = T)
```
The effect is positive (placebo) for low-income neighborhoods. However, it will
not be significant. It is not significant even with 0 income. 


```{r eval=FALSE, include=FALSE, results='asis'}
library(AER)

set.seed(seed)
reg_data <- read.csv("reg_data2.csv")
reg_data <- reg_data[sample(nrow(reg_data)), ]
reg_data <- reg_data[!duplicated(reg_data$id), ]

model <- ivreg(rating ~ log(review_count+1951) + price + I(price^2)|
                 log(review_count+1951) + StateRate +
                 CountyRate + CityRate + SpecialRate, data = reg_data)

summary(model)
library(ggeffects)
mydf <- ggpredict(model, terms = "price [all]")
plot(mydf)
```

```{r eval=FALSE, include=FALSE}
model <- lm(rating ~ StateRate + CountyRate + CityRate + SpecialRate,
            data = reg_data)
summary(model)

model <- lm(rating ~ review_count + price, data = reg_data)
summary(model)


model <- ivreg(rating ~ review_count + price| review_count + CombinedRate,
               data = reg_data)
summary(model)

model <- lm(price ~ CombinedRate, data = reg_data)
summary(model)

library(ggplot2)
ggplot(reg_data, aes(x = price, y = rating)) +
  geom_point()

```


## Latex

```{r eval=FALSE, include=FALSE, results='asis'}
stargazer(descr(raw_data[,6:8],
      stats = c("min", "q1", "med", "mean", "q3", "max"),
      style = "rmarkdown"),
      order = c(1,3,2,4))
```

```{r eval=FALSE, include=FALSE, results='asis'}
stargazer(descr(raw_data[,14:18],
      stats = c("min", "q1", "med", "mean", "q3", "max"),
      style = "rmarkdown"),
      order = c(1, 6, 2, 4, 5, 3))
```

```{r eval=FALSE, include=FALSE}
# Variable means
summary_table <- aggregate(raw_data[, c("rating", "price", "CombinedRate", "review_count")],
          list(raw_data$is_focal), mean, na.rm = T)[,2:5]
rownames(summary_table) <- c("Non-focal", "Focal")
summary_table <- mapply(round, summary_table, c(3,3,4,2))
summary_table <- apply(summary_table, 2, as.character)
stargazer(summary_table, summary = F)
```




